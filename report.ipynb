{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report\n",
    "__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## i. Which insights did you gain from your EDA? \n",
    ">\n",
    ">> * The native naive classifier in the raw dataset was quite ineffective. There were **8213** actual instances of fraud and it was only able to catch 16.\n",
    ">> * There are 8,213 total fraudlent transactions out of 6,362,620 overall transactions.\n",
    "* **Only 0.0001291% of all transactions are genuinely fradulent.** \n",
    "* There are 8,213 total fraudlent transactions out of 6,362,620 overall transactions.\n",
    "* **Only 0.0001291% of all transactions are fradulent.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## ii. How did you determine which columns to drop or keep? If your EDA informed this process, explain which insights you used to determine which columns were not needed. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## iii. Which hyperparameter tuning strategy did you use? Grid-search or random-search? Why?"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
