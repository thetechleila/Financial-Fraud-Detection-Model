{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## i. Which insights did you gain from your EDA? \n",
    ">\n",
    ">> * The native naive classifier in the raw dataset (the IsFlaggedFraud feature) was quite ineffective. There were **8213** actual instances of fraud and it was only able to catch 16.\n",
    ">>\n",
    ">> * The **IsFraud** feature is *not* strongly correlated with other numeric features in the dataset. This may be an indication that genuine fraud is not straightforwardly connected to numeric traits and is thusly more difficult to detect through using those traits.\n",
    ">>\n",
    ">> * There are 8,213 total fraudlent transactions out of 6,362,620 overall transactions.\n",
    ">>\n",
    ">> * The **IsFlaggedFraud** feature possesses no impactful correaltion to the **IsFraud** feature. This is further proof that the existing fraud classification method is highly ineffective.\n",
    ">>\n",
    ">> * **Only 0.0001291% of all transactions are genuinely fradulent.** \n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## ii. How did you determine which columns to drop or keep? If your EDA informed this process, explain which insights you used to determine which columns were not needed. \n",
    ">\n",
    ">> * The step, nameOrig, isFlaggedFraud, nameDest columns were removed as they were not needed to determine how best to find and accurately classify fraud. Removing them freed up more computational power to focus on the impactful features in the dataset.\n",
    ">>\n",
    ">> * The **IsFlaggedFraud** feature in particular was not useful as it only classified 16 transactions as fraud when there are 8,213 total fraud transactions. \n",
    ">>\n",
    ">> * There is also almost no impactful correlation between the **IsFlaggedFraud** feature's fraud labels and the count of real fraud from the **IsFraud** feature.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## iii. Which hyperparameter tuning strategy did you use? Grid-search or random-search? Why?\n",
    ">\n",
    ">> Random-Search was implemented due to the immense size of the dataset. A grid search of 6,362,620 rows and 11 columns would have been an unneeded expenditure of computational resources when only 8,213 transactions are genuinely fraudlent."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
